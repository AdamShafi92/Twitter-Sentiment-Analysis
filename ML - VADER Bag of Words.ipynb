{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import SentimentIntensityAnalyzer class \n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update VADER dictionary with financial lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dictionary from https://sraf.nd.edu/textual-analysis/resources/#Master%20Dictionary\n",
    "fin_dict = pd.read_csv('Financial Dictionary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop extra columns\n",
    "fin_dict = fin_dict.drop(['Sequence Number', 'Word Count', 'Word Proportion','Average Proportion', \n",
    "                          'Std Dev', 'Doc Count', 'Uncertainty', 'Litigious', 'Constraining', 'Superfluous',\n",
    "                          'Interesting', 'Modal', 'Irr_Verb', 'Harvard_IV', 'Syllables','Source'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean words\n",
    "fin_dict['Word'] = fin_dict['Word'].astype(str)\n",
    "fin_dict['Word'] = fin_dict['Word'].map(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get negative and positive words and give scores\n",
    "fin_dict_neg = fin_dict[fin_dict.Negative > 0]\n",
    "fin_dict_neg = fin_dict_neg.drop(['Negative','Positive'], axis=1)\n",
    "fin_dict_neg['score'] = -1\n",
    "fin_dict_pos = fin_dict[fin_dict.Positive > 0]\n",
    "fin_dict_pos = fin_dict_pos.drop(['Negative','Positive'], axis=1)\n",
    "fin_dict_pos['score'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to dictionary\n",
    "fin_dict_neg = fin_dict_neg.set_index('Word').T.to_dict('list')\n",
    "fin_dict_pos = fin_dict_pos.set_index('Word').T.to_dict('list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine negative and postive\n",
    "update_lexicon = fin_dict_neg\n",
    "update_lexicon.update(fin_dict_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_lexicon = {k:vs[0] for k,vs in update_lexicon.items()} # turn lists inside dictionary to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add some manual updates\n",
    "manual_updates = {\n",
    "    'sell' : -1,\n",
    "    'short': -1,\n",
    "    'shorts' : -1,\n",
    "    'monster' : 1,\n",
    "    'explode' : 1,\n",
    "    'explodes': 1,\n",
    "    'raised': 1,\n",
    "    'raise' : 1,\n",
    "    'share' : 0,\n",
    "    'shares' : 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_lexicon.update(manual_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "#update the lexicon with manual updates and financial vocabury\n",
    "Analyzer.lexicon.update(update_lexicon) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple ML using Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Tweets_clean_vader.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SentimentIntensityAnalyzer object. \n",
    "sid_obj = Analyzer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_scores1(sentence): \n",
    "    # polarity_scores method of SentimentIntensityAnalyzer \n",
    "    # oject gives a sentiment dictionary. \n",
    "    # which contains pos, neg, neu, and compound scores. \n",
    "    sentiment_dict = sid_obj.polarity_scores(sentence)   \n",
    "    return sentiment_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return a final score using a threshold\n",
    "def sentiment_scores2(sentence): \n",
    "    sentiment_dict = sid_obj.polarity_scores(sentence) \n",
    "    if sentiment_dict['compound'] >= 0.1 : \n",
    "        return(\"Positive\") \n",
    "    elif sentiment_dict['compound'] <= - 0.1 : \n",
    "        return(\"Negative\") \n",
    "    else : \n",
    "        return(\"Neutral\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['scores'] = df['clean_tweet'].apply(lambda x: sentiment_scores1(x))\n",
    "df['prediction'] = df['clean_tweet'].apply(lambda x: sentiment_scores2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map original labels to words to compare to VADER results\n",
    "di = {1: \"Positive\", 2: \"Neutral\", 0: \"Negative\"}\n",
    "df['Label_Map'] = df['Label'].map(di)\n",
    "df['result'] = np.where(df['Label_Map'] == df['prediction'], 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.538546255506608"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['result'].sum()/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('VADER_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive: ['precious']\n",
      "Neutral: ['wheaton', 'metals', 'corp', 'announces', 'quarterly', 'dividend', 'stocks']\n",
      "Negative: []\n",
      "\n",
      "Scores: {'neg': 0.0, 'neu': 0.654, 'pos': 0.346, 'compound': 0.5719}\n"
     ]
    }
   ],
   "source": [
    "#code to test any sentence\n",
    "\n",
    "sentence = 'wheaton precious metals corp announces quarterly dividend stocks'\n",
    "\n",
    "tokenized_sentence = word_tokenize(sentence)\n",
    "pos_word_list=[]\n",
    "neu_word_list=[]\n",
    "neg_word_list=[]\n",
    "\n",
    "for word in tokenized_sentence:\n",
    "    if (Analyzer.polarity_scores(word)['compound']) >= 0.1:\n",
    "        pos_word_list.append(word)\n",
    "    elif (Analyzer.polarity_scores(word)['compound']) <= -0.1:\n",
    "        neg_word_list.append(word)\n",
    "    else:\n",
    "        neu_word_list.append(word)                \n",
    "\n",
    "print('Positive:',pos_word_list)\n",
    "print('Neutral:',neu_word_list)\n",
    "print('Negative:',neg_word_list) \n",
    "score = Analyzer.polarity_scores(sentence)\n",
    "print('\\nScores:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
