{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "\n",
    "#NLTK Models\n",
    "from nltk import classify\n",
    "from nltk import NaiveBayesClassifier\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from nltk.metrics.scores import (precision, recall, f_measure)\n",
    "\n",
    "#SKLearn models can be used in NLTK\n",
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>emoji</th>\n",
       "      <th>Cashtags</th>\n",
       "      <th>hashtag_list</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['$SPX', '$SPY', '$ES', '$IXIC', '$DJI', '$QQQ']</td>\n",
       "      <td>['Markets', 'Stocks']</td>\n",
       "      <td>['market', 'stock']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label emoji                                          Cashtags  \\\n",
       "0      2   NaN  ['$SPX', '$SPY', '$ES', '$IXIC', '$DJI', '$QQQ']   \n",
       "\n",
       "            hashtag_list          clean_tweet  \n",
       "0  ['Markets', 'Stocks']  ['market', 'stock']  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Tweets_clean.csv')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-ML Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some extra processing is required here to ensure the lexicon only uses the training data - not words only in the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_tweet'] = df['clean_tweet'].apply(lambda x: literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "di = {1: \"Positive\", 2: \"Neutral\", 0: \"Negative\"}\n",
    "df['Label_Map'] = df['Label'].map(di) # map numbers to labes which we can use to create the data format for algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to create a dictionary of all words in the dictionary and true/false to check if there are in the tweet\n",
    "\n",
    "def all_tokens_for_model(tokens,label,all_words):\n",
    "    return [{word: (word in tokens) for word in all_words}, label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "910"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomise and split into training and test data\n",
    "\n",
    "df = df.sample(frac=1).reset_index(drop=True) #shuffle dataset\n",
    "df_train = df[:700]\n",
    "df_test  = df[700:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need to get all words in the training set to have the data in the format for the model\n",
    "\n",
    "all_words = set(word for passage in df_train['clean_tweet'] for word in passage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AdamShafi\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_train['ML_tweet'] = df.apply(lambda x:  all_tokens_for_model(x.clean_tweet,x.Label_Map, all_words), axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AdamShafi\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_test['ML_tweet'] = df.apply(lambda x:  all_tokens_for_model(x.clean_tweet,x.Label_Map, all_words), axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_clf = NaiveBayesClassifier.train(df_train['ML_tweet'])\n",
    "classify.accuracy(NB_clf, df_test['ML_tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                   short = True           Negati : Neutra =     35.2 : 1.0\n",
      "                 bearish = True           Negati : Neutra =     11.5 : 1.0\n",
      "                   lower = True           Negati : Neutra =      9.4 : 1.0\n",
      "                 billion = True           Negati : Neutra =      8.1 : 1.0\n",
      "                   daily = True           Negati : Neutra =      7.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "NB_clf.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6190476190476191"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNB_clf = SklearnClassifier(MultinomialNB())\n",
    "MNB_clf.train(df_train['ML_tweet'])\n",
    "classify.accuracy(MNB_clf, df_test['ML_tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5428571428571428"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BNB_clf = SklearnClassifier(BernoulliNB())\n",
    "BNB_clf.train(df_train['ML_tweet'])\n",
    "classify.accuracy(BNB_clf, df_test['ML_tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6476190476190476"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogReg_clf = SklearnClassifier(LogisticRegression(multi_class='multinomial', solver = 'lbfgs'))\n",
    "LogReg_clf.train(df_train['ML_tweet'])\n",
    "classify.accuracy(LogReg_clf, df_test['ML_tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6428571428571429"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGD_clf = SklearnClassifier(SGDClassifier(max_iter =1000, tol=.1))\n",
    "SGD_clf.train(df_train['ML_tweet'])\n",
    "classify.accuracy(SGD_clf, df_test['ML_tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4666666666666667"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVC_clf = SklearnClassifier(SVC(gamma='auto'))\n",
    "SVC_clf.train(df_train['ML_tweet'])\n",
    "classify.accuracy(SVC_clf, df_test['ML_tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6190476190476191"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT_clf = SklearnClassifier(DecisionTreeClassifier())\n",
    "DT_clf.train(df_train['ML_tweet'])\n",
    "classify.accuracy(DT_clf, df_test['ML_tweet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_data(classifier,data): #this outputs just a result, negative or positive\n",
    "    data = data[0] # the data is currently a list containing a dictionary and the label. This just gets the dictionary\n",
    "    return classifier.classify(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AdamShafi\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "#test all models on the data to compare results\n",
    "\n",
    "algos = [NB_clf, MNB_clf, BNB_clf, LogReg_clf, SGD_clf, SVC_clf]\n",
    "for i in algos:\n",
    "    df_test[i] = df_test['ML_tweet'].apply(lambda x: classify_data(i, x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns and save results\n",
    "df_test.columns = ['Label', 'Emoji','Cashtags','Hashtags','Clean_Tweet','Label_Name','ML_tweet', 'NB', 'MNB', 'BNB','LogReg','SDG','SVC']\n",
    "df_test.to_csv('testing.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(columns=['Algorithm', 'Accuracy','Precision','Recall','F1_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results['Algorithm'] = ['NB_clf', 'MNB_clf', 'BNB_clf', 'LogReg_clf', 'SGD_clf', 'SVC_clf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[]\n",
    "for i in algos:\n",
    "    a.append(classify.accuracy(i, df_test['ML_tweet']))\n",
    "df_results['Accuracy'] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Refset = set(df_test[df_test.Label_Name.eq('Positive')].index) #NLTK requires a 'set' for precision, recall and F1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results['Precision'] =[\n",
    "    precision(Refset,set(df_test[df_test.NB.eq('Positive')].index)),\n",
    "    precision(Refset,set(df_test[df_test.MNB.eq('Positive')].index)),\n",
    "    precision(Refset,set(df_test[df_test.BNB.eq('Positive')].index)),\n",
    "    precision(Refset,set(df_test[df_test.LogReg.eq('Positive')].index)),\n",
    "    precision(Refset,set(df_test[df_test.SDG.eq('Positive')].index)),\n",
    "    precision(Refset,set(df_test[df_test.SVC.eq('Positive')].index))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results['Recall'] =[\n",
    "    recall(Refset,set(df_test[df_test.NB.eq('Positive')].index)),\n",
    "    recall(Refset,set(df_test[df_test.MNB.eq('Positive')].index)),\n",
    "    recall(Refset,set(df_test[df_test.BNB.eq('Positive')].index)),\n",
    "    recall(Refset,set(df_test[df_test.LogReg.eq('Positive')].index)),\n",
    "    recall(Refset,set(df_test[df_test.SDG.eq('Positive')].index)),\n",
    "    recall(Refset,set(df_test[df_test.SVC.eq('Positive')].index))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results['F1_score'] =[\n",
    "    f_measure(Refset,set(df_test[df_test.NB.eq('Positive')].index), alpha=0.5),\n",
    "    f_measure(Refset,set(df_test[df_test.MNB.eq('Positive')].index), alpha=0.5),\n",
    "    f_measure(Refset,set(df_test[df_test.BNB.eq('Positive')].index), alpha=0.5),\n",
    "    f_measure(Refset,set(df_test[df_test.LogReg.eq('Positive')].index), alpha=0.5),\n",
    "    f_measure(Refset,set(df_test[df_test.SDG.eq('Positive')].index), alpha=0.5),\n",
    "    f_measure(Refset,set(df_test[df_test.SVC.eq('Positive')].index), alpha=0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NB_clf</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.557143</td>\n",
       "      <td>0.493671</td>\n",
       "      <td>0.523490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MNB_clf</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.561644</td>\n",
       "      <td>0.518987</td>\n",
       "      <td>0.539474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BNB_clf</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.558140</td>\n",
       "      <td>0.303797</td>\n",
       "      <td>0.393443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogReg_clf</td>\n",
       "      <td>0.647619</td>\n",
       "      <td>0.602564</td>\n",
       "      <td>0.594937</td>\n",
       "      <td>0.598726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SGD_clf</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.626866</td>\n",
       "      <td>0.531646</td>\n",
       "      <td>0.575342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVC_clf</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Algorithm  Accuracy  Precision    Recall  F1_score\n",
       "0      NB_clf  0.600000   0.557143  0.493671  0.523490\n",
       "1     MNB_clf  0.619048   0.561644  0.518987  0.539474\n",
       "2     BNB_clf  0.542857   0.558140  0.303797  0.393443\n",
       "3  LogReg_clf  0.647619   0.602564  0.594937  0.598726\n",
       "4     SGD_clf  0.642857   0.626866  0.531646  0.575342\n",
       "5     SVC_clf  0.466667        NaN  0.000000       NaN"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#output results\n",
    "df_results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model for production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrain best model with the full dataset\n",
    "\n",
    "all_words = set(word for passage in df['clean_tweet'] for word in passage)\n",
    "df['ML_tweet'] = df.apply(lambda x:  all_tokens_for_model(x.clean_tweet,x.Label_Map, all_words), axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SklearnClassifier(LogisticRegression(multi_class='multinomial'))>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogReg_clf = SklearnClassifier(LogisticRegression(multi_class='multinomial', solver = 'lbfgs'))\n",
    "LogReg_clf.train(df['ML_tweet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickling models - 2 ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def pickler(model, name):\n",
    "    pickle.dump(model, open(filepath+'\\\\'+name, 'wb'))\n",
    "filepath = r'C:\\Users\\AdamShafi\\Twitter Sentiment Analysis\\Pickled Algos'\n",
    "names = ('NB_clf.sav','MNB_clf.sav', 'BNB_clf.sav', 'LogReg_clf.sav', 'SGD_clf.sav', 'SVC_clf.sav')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in zip(algos, names): #individual files\n",
    "    pickler(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIK = filepath+'\\\\'+'pickle.dat' #one pickle file\n",
    "\n",
    "with open(PIK, \"wb\") as f:\n",
    "    pickle.dump(algos, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle corpus\n",
    "with open('all_words.pkl', 'wb') as f:\n",
    "    pickle.dump(all_words, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/text-preprocessing-steps-and-universal-pipeline-94233cb6725a\n",
    "#https://sebastianraschka.com/Articles/2014_multiprocessing.html\n",
    "#https://www.digitalocean.com/community/tutorials/how-to-perform-sentiment-analysis-in-python-3-using-the-natural-language-toolkit-nltk\n",
    "#https://stackoverflow.com/questions/20827741/nltk-naivebayesclassifier-training-for-sentiment-analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
